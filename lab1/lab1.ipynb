{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import psycopg2\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().joinpath('data')\n",
    "SQL_DIR = Path.cwd().joinpath('sql')\n",
    "AIRCRAFTS_DIR = DATA_DIR.joinpath('aircrafts')\n",
    "AIRCRAFTS_FILTERED_DIR = DATA_DIR.joinpath('aircrafts_filtered')\n",
    "ROUTES_DIR = DATA_DIR.joinpath('routes')\n",
    "ROUTES_FILTERED_DIR = DATA_DIR.joinpath('routes_filtered')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "DB_HOST = 'localhost'\n",
    "DB_PORT = 5432\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = r'zWKHqx1N3%Gt'\n",
    "DB_NAME = 'data_analysis_lab1'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "FR24_DTYPES = {\n",
    "    'flight_id': object,\n",
    "    'icao24': object,\n",
    "    'latitude': float,\n",
    "    'longitude': float,\n",
    "    'heading': int,\n",
    "    'height': int,\n",
    "    'airspeed': int,\n",
    "    'squawk': float,\n",
    "    'locator': object,\n",
    "    'aircraft': object,\n",
    "    'registration': object,\n",
    "    'unixtime': int,\n",
    "    'departure': object,\n",
    "    'arrival': object,\n",
    "    'ticket_route': object,\n",
    "    'status': int,\n",
    "    'vertical_speed': int,\n",
    "    'transponder_route': object,\n",
    "    'airline': object,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "SYMBOL_REPLACES = {\n",
    "    '\\u00c0': 'A',\n",
    "    '\\u00c1': 'A',\n",
    "    '\\u00c2': 'A',\n",
    "    '\\u00c3': 'A',\n",
    "    '\\u00c4': 'A',\n",
    "    '\\u00c5': 'A',\n",
    "    '\\u00c6': 'A',\n",
    "    '\\u00c7': 'C',\n",
    "    '\\u00c8': 'E',\n",
    "    '\\u00c9': 'E',\n",
    "    '\\u00ca': 'E',\n",
    "    '\\u00cb': 'E',\n",
    "    '\\u00cc': 'I',\n",
    "    '\\u00cd': 'I',\n",
    "    '\\u00ce': 'I',\n",
    "    '\\u00cf': 'I',\n",
    "    '\\u00d1': 'N',\n",
    "    '\\u00d2': 'O',\n",
    "    '\\u00d3': 'O',\n",
    "    '\\u00d4': 'O',\n",
    "    '\\u00d5': 'O',\n",
    "    '\\u00d6': 'O',\n",
    "    '\\u00d8': 'O',\n",
    "    '\\u00d9': 'U',\n",
    "    '\\u00da': 'U',\n",
    "    '\\u00db': 'U',\n",
    "    '\\u00dc': 'U',\n",
    "    '\\u00dd': 'Y',\n",
    "    '\\u00df': 'S',\n",
    "    '\\u00e0': 'a',\n",
    "    '\\u00e1': 'a',\n",
    "    '\\u00e2': 'a',\n",
    "    '\\u00e3': 'a',\n",
    "    '\\u00e4': 'a',\n",
    "    '\\u00e5': 'a',\n",
    "    '\\u00e6': 'a',\n",
    "    '\\u00e7': 'c',\n",
    "    '\\u00e8': 'e',\n",
    "    '\\u00e9': 'e',\n",
    "    '\\u00ea': 'e',\n",
    "    '\\u00eb': 'e',\n",
    "    '\\u00ec': 'i',\n",
    "    '\\u00ed': 'i',\n",
    "    '\\u00ee': 'i',\n",
    "    '\\u00ef': 'i',\n",
    "    '\\u00f0': 'd',\n",
    "    '\\u00f1': 'n',\n",
    "    '\\u00f2': 'o',\n",
    "    '\\u00f3': 'o',\n",
    "    '\\u00f4': 'o',\n",
    "    '\\u00f5': 'o',\n",
    "    '\\u00f6': 'รถ',\n",
    "    '\\u00f8': 'o',\n",
    "    '\\u00f9': 'u',\n",
    "    '\\u00fa': 'u',\n",
    "    '\\u00fb': 'u',\n",
    "    '\\u00fc': 'u',\n",
    "    '\\u00fd': 'y',\n",
    "    '\\u00ff': 'y',\n",
    "    '\\u200b': '',\n",
    "    '\\xa0': ' '\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_aircraft_designators():\n",
    "    response = requests.post(\n",
    "        url='https://www4.icao.int/doc8643/External/AircraftTypes'\n",
    "    )\n",
    "\n",
    "    content = response.content.decode(response.encoding)\n",
    "    json_content = json.loads(content)\n",
    "    designators_data = pd.DataFrame.from_records(json_content)\n",
    "    special_designators = pd.read_csv(DATA_DIR.joinpath('special_designators.csv'))\n",
    "\n",
    "    designators = pd.concat([designators_data, special_designators])\n",
    "\n",
    "    designators.columns = ['name', 'description', 'turbulence_category', 'WTG', 'designator', 'manufacturer', 'type',\n",
    "                           'engine_count', 'engine_type']\n",
    "    designators.engine_count = designators.engine_count.str.replace(r'[^\\d]+', '1', regex=True)\n",
    "\n",
    "    designators.to_csv(DATA_DIR.joinpath('designators.csv'), index=False,\n",
    "                       columns=['name', 'description', 'turbulence_category', 'designator', 'manufacturer', 'type',\n",
    "                                'engine_count', 'engine_type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_unique_data():\n",
    "    registrations = []\n",
    "    routes = []\n",
    "    for index, file in enumerate(\n",
    "            list(DATA_DIR.joinpath('fr24').iterdir())[0:]):\n",
    "        try:\n",
    "            data = pd.read_csv(file, names=FR24_DTYPES.keys(), on_bad_lines='skip', dtype=FR24_DTYPES)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        unique_registrations = data.registration.dropna().unique()\n",
    "        registrations.append(unique_registrations)\n",
    "\n",
    "        unique_routes = data.ticket_route.dropna().unique()\n",
    "        routes.append(unique_routes)\n",
    "    registrations = np.unique(np.concatenate(registrations))\n",
    "    routes = np.unique(np.concatenate(routes))\n",
    "    return registrations, routes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_aircrafts_info(filename):\n",
    "    registrations = pd.read_csv(filename, names=['registration'])\n",
    "\n",
    "    registrations = registrations.sample(frac=1)\n",
    "\n",
    "    progress_bar = tqdm.tqdm(registrations.registration)\n",
    "    for registration in progress_bar:\n",
    "        progress_bar.set_description(f'Fetching {registration}')\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url='https://api.flightradar24.com/common/v1/flight/list.json?'\n",
    "                    'enc=IKQGxn3NR31_n-55iS2uKcuzjmvSFrtJX6mpRJYT7oI&'\n",
    "                    f'query={registration}&'\n",
    "                    'fetchBy=reg&'\n",
    "                    'limit=1&'\n",
    "                    'timestamp=0&'\n",
    "                    'page=1&'\n",
    "                    'filterBy=&'\n",
    "                    'token=IKQGxn3NR31_n-55iS2uKcuzjmvSFrtJX6mpRJYT7oI&'\n",
    "                    'client=ios_freemium&'\n",
    "                    'version=9.2.1',\n",
    "                headers={\n",
    "                    'User-Agent': 'FlightradarFree/2023021501 CFNetwork/1404.0.5 Darwin/22.3.0'\n",
    "                }\n",
    "            )\n",
    "            with open(f'aircrafts\\\\{registration}.json', 'w', encoding=response.encoding) as file:\n",
    "                file.write(response.content.decode(response.encoding))\n",
    "            time.sleep(0.6)\n",
    "        except:\n",
    "            ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_routes_info(filename: 'str | Path'):\n",
    "    routes = pd.read_csv(filename, names=['route'])\n",
    "\n",
    "    routes = routes.sample(frac=1)\n",
    "\n",
    "    progress_bar = tqdm.tqdm(routes.route)\n",
    "\n",
    "    for route in progress_bar:\n",
    "        progress_bar.set_description(f'Fetching {routes}')\n",
    "        progress_bar.refresh()\n",
    "        page = 1\n",
    "        last = None\n",
    "        while True:\n",
    "            time.sleep(0.6)\n",
    "\n",
    "            response = requests.get(\n",
    "                url='https://api.flightradar24.com/common/v1/flight/list.json?'\n",
    "                    'enc=6pDfb2KZPxots_3kFVasmNL1WJ7rQXvJ5yJb4NhegjA&'\n",
    "                    f'query={route}&'\n",
    "                    'fetchBy=flight&'\n",
    "                    'limit=100&'\n",
    "                    f'page={page}&'\n",
    "                    'token=6pDfb2KZPxots_3kFVasmNL1WJ7rQXvJ5yJb4NhegjA',\n",
    "                headers={\n",
    "                    'User-Agent': 'FlightradarFree/2023021501 CFNetwork/1404.0.5 Darwin/22.3.0'\n",
    "                }\n",
    "            )\n",
    "            content = response.content.decode(response.encoding)\n",
    "\n",
    "            debug_name = DATA_DIR.joinpath(f'debug\\\\{uuid.uuid4()}.json')\n",
    "\n",
    "            with open(debug_name, 'w') as file:\n",
    "                file.write(content)\n",
    "\n",
    "            if '402 Payment Required' in content or 'Error reference number' in content:\n",
    "                break\n",
    "\n",
    "            json_data = json.loads(content)\n",
    "            if 'errors' in json_data:\n",
    "                break\n",
    "            elif 'result' not in json_data:\n",
    "                break\n",
    "            elif 'response' not in json_data['result']:\n",
    "                break\n",
    "\n",
    "            result = json_data['result']['response']\n",
    "\n",
    "            respath = ROUTES_DIR.joinpath(f'{route}_{page}.json')\n",
    "\n",
    "            with open(respath, 'w') as file:\n",
    "                json.dump(json_data, file)\n",
    "\n",
    "            if 'page' not in result:\n",
    "                break\n",
    "\n",
    "            data = result['data']\n",
    "\n",
    "            if data is None or (last is not None and data[0] == last):\n",
    "                respath.unlink()\n",
    "                break\n",
    "\n",
    "            if not result['page']['more']:\n",
    "                break\n",
    "\n",
    "            page += 1\n",
    "            last = data[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def filter_aircrafts():\n",
    "    progress_bar = tqdm.tqdm(AIRCRAFTS_DIR.iterdir())\n",
    "    for filename in progress_bar:\n",
    "        progress_bar.set_description(f'Checking {filename.name}')\n",
    "        if filename.suffix == '.json':\n",
    "            with open(filename) as file:\n",
    "                content = file.read()\n",
    "            if '402 Payment Required' in content or 'Cloudflare Location' in content:\n",
    "                filename.unlink()\n",
    "            else:\n",
    "                json_data = json.loads(content)\n",
    "                if 'errors' not in json_data:\n",
    "                    aircraftInfo = json_data['result']['response']['aircraftInfo']\n",
    "                    if aircraftInfo:\n",
    "                        with open(DATA_DIR.joinpath('aircrafts_filtered').joinpath(filename.name), 'w') as file:\n",
    "                            json.dump(json_data['result']['response']['aircraftInfo'], file)\n",
    "        else:\n",
    "            filename.unlink()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def filter_routes():\n",
    "    progress_bar = tqdm.tqdm(list(ROUTES_DIR.iterdir()))\n",
    "    for filename in progress_bar:\n",
    "        progress_bar.set_description(f'Checking {filename.name}')\n",
    "        if filename.suffix == '.json':\n",
    "            with open(filename) as file:\n",
    "                content = file.read()\n",
    "            json_data = json.loads(content)\n",
    "            if 'errors' not in json_data:\n",
    "                response = json_data['result']['response']\n",
    "                if 'data' in response and response['data']:\n",
    "                    with open(ROUTES_FILTERED_DIR.joinpath(filename.name), 'w') as file:\n",
    "                        json.dump(response['data'], file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def routes_to_csv():\n",
    "    def check_data(data) -> bool:\n",
    "        if 'identification' in data:\n",
    "            if 'id' in data['identification']:\n",
    "                return data['identification']['id'] is not None\n",
    "        return False\n",
    "\n",
    "    csv_path = DATA_DIR.joinpath('flights.csv')\n",
    "    if csv_path.exists():\n",
    "        csv_path.unlink()\n",
    "\n",
    "    progress_bar = tqdm.tqdm(list(ROUTES_FILTERED_DIR.iterdir()))\n",
    "\n",
    "    for filename in progress_bar:\n",
    "        progress_bar.set_description(f'Adding {filename.name}')\n",
    "        progress_bar.refresh()\n",
    "        with open(filename) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            airline_icao = ''\n",
    "            flights = []\n",
    "            for index, row in enumerate(filter(check_data, json_data)):\n",
    "                if 'status' in row:\n",
    "                    if row['status']['live']:\n",
    "                        continue\n",
    "                route_number_regex = re.match('(?P<number>.+)_.+', filename.name)\n",
    "                route_number = route_number_regex.group('number')\n",
    "                flight_id = row['identification']['id']\n",
    "                aircraft_registration = ''\n",
    "                airport_origin = ''\n",
    "                airport_destination = ''\n",
    "                scheduled_departure = ''\n",
    "                scheduled_arrival = ''\n",
    "                real_departure = ''\n",
    "                real_arrival = ''\n",
    "\n",
    "                if 'aircraft' in row:\n",
    "                    aircraft = row['aircraft']\n",
    "                    if aircraft and 'registration' in aircraft:\n",
    "                        aircraft_registration = row['aircraft']['registration']\n",
    "                if not airline_icao and 'airline' in row:\n",
    "                    airline = row['airline']\n",
    "                    if airline and 'code' in airline:\n",
    "                        code = airline['code']\n",
    "                        if code and 'icao' in code:\n",
    "                            airline_icao = code['icao']\n",
    "                if 'airport' in row:\n",
    "                    airport = row['airport']\n",
    "                    if airport:\n",
    "                        if 'origin' in airport:\n",
    "                            origin = airport['origin']\n",
    "                            if origin and 'code' in origin:\n",
    "                                code = origin['code']\n",
    "                                if code and 'icao' in code:\n",
    "                                    airport_origin = code['icao']\n",
    "                        if 'destination' in airport:\n",
    "                            destination = airport['destination']\n",
    "                            if destination and 'code' in destination:\n",
    "                                code = destination['code']\n",
    "                                if code and 'icao' in code:\n",
    "                                    airport_destination = code['icao']\n",
    "                if 'time' in row:\n",
    "                    route_times = row['time']\n",
    "                    if route_times:\n",
    "                        if 'scheduled' in route_times:\n",
    "                            scheduled_times = route_times['scheduled']\n",
    "                            if scheduled_times:\n",
    "                                if 'departure' in scheduled_times:\n",
    "                                    scheduled_departure = scheduled_times['departure']\n",
    "                                if 'arrival' in scheduled_times:\n",
    "                                    scheduled_arrival = scheduled_times['arrival']\n",
    "                        if 'real' in route_times:\n",
    "                            real_times = route_times['real']\n",
    "                            if real_times:\n",
    "                                if 'departure' in real_times:\n",
    "                                    real_departure = real_times['departure']\n",
    "                                if 'arrival' in real_times:\n",
    "                                    real_arrival = real_times['arrival']\n",
    "                flights.append([int(flight_id, 16), route_number, aircraft_registration, airline_icao,\n",
    "                                airport_origin, airport_destination,\n",
    "                                scheduled_departure, scheduled_arrival, real_departure,\n",
    "                                real_arrival])\n",
    "            if airline_icao:\n",
    "                for flight in flights:\n",
    "                    flight[3] = airline_icao\n",
    "            with open(csv_path, 'a', newline='') as file:\n",
    "                csv_writer = csv.writer(file)\n",
    "                csv_writer.writerows(flights)\n",
    "\n",
    "    dtypes = {\n",
    "        'flight_id': int,\n",
    "        'route_number': object,\n",
    "        'aircraft_registration': object,\n",
    "        'airline_icao': object,\n",
    "        'airport_origin': object,\n",
    "        'airport_destination': object,\n",
    "        'scheduled_departure': object,\n",
    "        'scheduled_arrival': object,\n",
    "        'real_departure': float,\n",
    "        'real_arrival': float\n",
    "    }\n",
    "    data = pd.read_csv(\n",
    "        csv_path,\n",
    "        names=dtypes.keys()\n",
    "    )\n",
    "\n",
    "    data = data.drop_duplicates(subset='flight_id')\n",
    "    data.to_csv(csv_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_missing_aircrafts():\n",
    "    dtypes = {\n",
    "        'flight_id': str,\n",
    "        'route_number': str,\n",
    "        'aircraft_registration': str,\n",
    "        'airline_icao': str,\n",
    "        'airport_origin': str,\n",
    "        'airport_destination': str,\n",
    "        'scheduled_departure': str,\n",
    "        'scheduled_arrival': str,\n",
    "        'real_departure': float,\n",
    "        'real_arrival': float\n",
    "    }\n",
    "    data = pd.read_csv(\n",
    "        DATA_DIR.joinpath('routes_filtered.csv'),\n",
    "        names=dtypes.keys(),\n",
    "        dtype=dtypes,\n",
    "        index_col='flight_id'\n",
    "    )\n",
    "\n",
    "    aircrafts_aircrafts = set(map(lambda p: p.stem, DATA_DIR.joinpath('aircrafts_filtered').iterdir()))\n",
    "    routes_aircrafts = set(data.aircraft_registration.unique())\n",
    "\n",
    "    with open(DATA_DIR.joinpath('missed_aircrafts.csv'), 'w') as file:\n",
    "        file.write('\\n'.join(map(str, routes_aircrafts - aircrafts_aircrafts)))\n",
    "\n",
    "    get_aircrafts_info(DATA_DIR.joinpath('missed_aircrafts.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def aircrafts_to_csv():\n",
    "    csv_path = DATA_DIR.joinpath('aircrafts_filtered.csv')\n",
    "    with open(csv_path, 'w', newline='') as csv_file:\n",
    "        csw_writer = csv.writer(csv_file)\n",
    "        csw_writer.writerow([\n",
    "            'registration',\n",
    "            'model_code',\n",
    "            'model_text',\n",
    "            'country_code',\n",
    "            'production_date',\n",
    "            'owner_icao'\n",
    "        ])\n",
    "\n",
    "    progress_bar = tqdm.tqdm(list(AIRCRAFTS_FILTERED_DIR.iterdir()))\n",
    "\n",
    "    for filename in progress_bar:\n",
    "        # for filename in [AIRCRAFTS_FILTERED_DIR.joinpath('D-EEEH.json')]:\n",
    "        progress_bar.set_description(f'Adding {filename.name}')\n",
    "        progress_bar.refresh()\n",
    "        with open(filename) as json_file:\n",
    "            try:\n",
    "                json_data = json.load(json_file)\n",
    "            except:\n",
    "                continue\n",
    "            registration = filename.stem\n",
    "\n",
    "            model_code = None\n",
    "            model_text = None\n",
    "            country_code = None\n",
    "            production_date = None\n",
    "            owner_icao = None\n",
    "\n",
    "            if 'model' in json_data:\n",
    "                model = json_data['model']\n",
    "                if model:\n",
    "                    if 'code' in model:\n",
    "                        model_code = model['code']\n",
    "                    if 'text' in model:\n",
    "                        model_text = model['text']\n",
    "                        if model_text:\n",
    "                            for original, to_replace in SYMBOL_REPLACES.items():\n",
    "                                model_text = model_text.replace(original, to_replace)\n",
    "\n",
    "            if 'country' in json_data:\n",
    "                country = json_data['country']\n",
    "                if country and 'alpha2' in country:\n",
    "                    country_code = country['alpha2']\n",
    "\n",
    "            if 'age' in json_data:\n",
    "                age = json_data['age']\n",
    "                if age and 'date' in age and age['date']:\n",
    "                    production_date = dt.datetime.strptime(age['date'], '%b %Y').date()\n",
    "\n",
    "            if 'owner' in json_data:\n",
    "                owner = json_data['owner']\n",
    "                if owner and 'code' in owner:\n",
    "                    code = owner['code']\n",
    "                    if 'icao' in code:\n",
    "                        owner_icao = code['icao']\n",
    "            with open(csv_path, 'a', newline='') as file:\n",
    "                csv_writer = csv.writer(file)\n",
    "                csv_writer.writerow([\n",
    "                    registration,\n",
    "                    model_code,\n",
    "                    model_text,\n",
    "                    country_code,\n",
    "                    production_date,\n",
    "                    owner_icao\n",
    "                ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_airports():\n",
    "    airports = pd.read_csv('https://davidmegginson.github.io/ourairports-data/airports.csv', header=0, names=[\n",
    "        'airport_id',\n",
    "        'code',\n",
    "        'type',\n",
    "        'name',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'elevation',\n",
    "        'continent',\n",
    "        'country',\n",
    "        'region',\n",
    "        'municipality',\n",
    "        'scheduled_service',\n",
    "        'gps_code',\n",
    "        'iata_code',\n",
    "        'local_code',\n",
    "        'home_link',\n",
    "        'wikipedia_link',\n",
    "        'keywords'\n",
    "    ], keep_default_na=False)\n",
    "\n",
    "    airports.to_csv(DATA_DIR.joinpath('airports.csv'), columns=[\n",
    "        'code',\n",
    "        'type',\n",
    "        'name',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'elevation',\n",
    "        'region',\n",
    "        'gps_code'\n",
    "    ], index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_countries():\n",
    "    countries = pd.read_csv('https://davidmegginson.github.io/ourairports-data/countries.csv', header=0, names=[\n",
    "        'country_id',\n",
    "        'code',\n",
    "        'name',\n",
    "        'continent',\n",
    "        'wikipedia_link',\n",
    "        'keywords'\n",
    "    ], keep_default_na=False)\n",
    "    countries.to_csv(DATA_DIR.joinpath('countries.csv'), columns=[\n",
    "        'code',\n",
    "        'name',\n",
    "        'continent'\n",
    "    ], index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_regions():\n",
    "    regions = pd.read_csv('https://davidmegginson.github.io/ourairports-data/regions.csv', header=0, names=[\n",
    "        'region_id',\n",
    "        'code',\n",
    "        'local_coe',\n",
    "        'name',\n",
    "        'continent',\n",
    "        'country',\n",
    "        'wikipedia_link',\n",
    "        'keywords'\n",
    "    ], keep_default_na=False)\n",
    "    regions.to_csv(DATA_DIR.joinpath('regions.csv'), columns=[\n",
    "        'code',\n",
    "        'name',\n",
    "        'country'\n",
    "    ], index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_airlines():\n",
    "    airlines = pd.read_csv('https://raw.githubusercontent.com/jpatokal/openflights/master/data/airlines.dat',\n",
    "                           header=None, names=[\n",
    "            'airline_id',\n",
    "            'name',\n",
    "            'alias',\n",
    "            'iata_code',\n",
    "            'code',\n",
    "            'callsign',\n",
    "            'country',\n",
    "            'active'\n",
    "        ], keep_default_na=False)\n",
    "    airlines.active = airlines.active.str.upper().map({'Y': True, 'N': False})\n",
    "    airlines.to_csv(DATA_DIR.joinpath('airlines.csv'), columns=[\n",
    "        'airline_id',\n",
    "        'name',\n",
    "        'alias',\n",
    "        'code',\n",
    "        'callsign',\n",
    "        'country',\n",
    "        'active'\n",
    "    ], index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def generate_dates(\n",
    "        start_date=dt.datetime(year=1900, month=1, day=1, tzinfo=pytz.UTC),\n",
    "        last_date=dt.datetime.now(tz=pytz.UTC)\n",
    "):\n",
    "    if start_date.tzinfo != pytz.UTC or last_date.tzinfo != pytz.UTC:\n",
    "        raise ValueError('Time zone must be UTC')\n",
    "\n",
    "    rows = [\n",
    "        ['the_date', 'weekday', 'month', 'year', 'quarter', 'day_of_year', 'weekend', 'week_of_year']\n",
    "    ]\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < last_date:\n",
    "        the_date = current_date.date()\n",
    "        weekday = current_date.weekday()\n",
    "        month = current_date.month\n",
    "        year = current_date.year\n",
    "        quarter = (current_date.month - 1) // 3\n",
    "        day_of_year = current_date.timetuple().tm_yday\n",
    "        weekend = 5 <= weekday\n",
    "        week_of_year = current_date.isocalendar()[1]\n",
    "        rows.append([the_date, weekday, month, year, quarter, day_of_year, weekend, week_of_year])\n",
    "        current_date += dt.timedelta(days=1)\n",
    "\n",
    "    with open(DATA_DIR.joinpath('dates.csv'), 'w', newline='') as csv_file:\n",
    "        csw_writer = csv.writer(csv_file)\n",
    "        csw_writer.writerows(rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    aircrafts_to_csv()\n",
    "    get_airlines()\n",
    "    get_airports()\n",
    "    get_countries()\n",
    "    generate_dates()\n",
    "    get_aircraft_designators()\n",
    "    routes_to_csv()\n",
    "    get_regions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def load_to_stage():\n",
    "    conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASSWORD)\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('TRUNCATE stage.aircrafts;')\n",
    "    cursor.execute('TRUNCATE stage.airlines;')\n",
    "    cursor.execute('TRUNCATE stage.airports;')\n",
    "    cursor.execute('TRUNCATE stage.continents;')\n",
    "    cursor.execute('TRUNCATE stage.countries;')\n",
    "    cursor.execute('TRUNCATE stage.designators;')\n",
    "    cursor.execute('TRUNCATE stage.flights;')\n",
    "    cursor.execute('TRUNCATE stage.regions;')\n",
    "    cursor.execute('TRUNCATE stage.dates;')\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.aircrafts (registration, model_code, model_text, country_code, production_date, owner_icao) FROM '{DATA_DIR.joinpath('aircrafts_filtered.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.airlines (airline_id, name, alias, code, callsign, country, active) FROM '{DATA_DIR.joinpath('airlines.csv')}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.airports (code, type, name, latitude, longitude, elevation, region, gps_code) FROM '{DATA_DIR.joinpath('airports.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.continents (code, name) FROM '{DATA_DIR.joinpath('continents.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.countries (code, name, continent) FROM '{DATA_DIR.joinpath('countries.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.designators (name, description, turbulence_category, designator, manufacturer, type, engine_count, engine_type) FROM '{DATA_DIR.joinpath('designators.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.flights (flight_id, route_number, aircraft_registration, airline_icao, airport_origin, airport_destination, scheduled_departure, scheduled_arrival, real_departure, real_arrival) FROM '{DATA_DIR.joinpath('flights.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.regions (code, name, country) FROM '{DATA_DIR.joinpath('regions.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"COPY stage.dates (the_date, weekday, month, year, quarter, day_of_year, weekend, week_of_year) FROM '{DATA_DIR.joinpath('dates.csv').absolute()}' DELIMITER ',' CSV HEADER;\")\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def link_models(conn: str):\n",
    "    aircrafts = pd.read_sql_table('aircrafts', conn, schema='stage', index_col='aircraft_id')\n",
    "    designators = pd.read_sql_table('designators_dim', conn, index_col='model_id')\n",
    "    results = []\n",
    "    progress_bar = tqdm.tqdm(list(aircrafts.iterrows()))\n",
    "    for row in progress_bar:\n",
    "        _, model_code, model_text, *_ = row[1]\n",
    "        progress_bar.set_description(f'{model_code} | {model_text}')\n",
    "        progress_bar.refresh()\n",
    "        variants = designators.query(f'designator == \"{model_code}\"').name\n",
    "        result = None\n",
    "        if model_text and not variants.empty:\n",
    "            ratios = np.array([SequenceMatcher(None, model_text, variant).ratio() for variant in variants])\n",
    "            result = variants.iloc[ratios.argmax()]\n",
    "        results.append(result)\n",
    "    aircrafts['linked_model_text'] = results\n",
    "    return aircrafts\n",
    "if (3 == 3 and\n",
    "    4 == 5):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def stage_to_fact():\n",
    "    conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASSWORD)\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    with open(SQL_DIR.joinpath('etl1.sql')) as file:\n",
    "        cursor.execute(file.read())\n",
    "\n",
    "    conn = f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "    linked_aircrafts = link_models(conn)\n",
    "    linked_aircrafts.to_sql('temp_aircrafts', conn)\n",
    "\n",
    "    with open(SQL_DIR.joinpath('etl2.sql')) as file:\n",
    "        cursor.execute(file.read())\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "load_to_stage()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B77L | Boeing 777-FS2:  70%|โโโโโโโ   | 19094/27410 [01:45<00:46, 177.98it/s]                            "
     ]
    }
   ],
   "source": [
    "stage_to_fact()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding ZW3624_1.json: 100%|โโโโโโโโโโ| 3190/3190 [00:18<00:00, 169.08it/s] \n"
     ]
    }
   ],
   "source": [
    "routes_to_csv()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def etl():\n",
    "    load_to_stage()\n",
    "    stage_to_fact()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
